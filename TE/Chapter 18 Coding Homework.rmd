---
title: "Chapter 18 Coding Homework"
author: "Allyson Cameron"
date: "03-29-2023"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
library(Statamarkdown)
```

# Word Questions\ 

## How Does It Work? \

> 1.  In the Event Studies chapter we estimated the effect of something that occurs at a specific time by just comparing before-event to after-event, without really using a control group. What assumption is made by no-control-group event studies that we don't have to make with difference-in-differences?

Event studies assume that the before treatment information can be used to construct a counter-factual, however with difference in difference they are instead adds another group that is never treated instead of using the before treatment information as the jumping off point of comparison like with event studies.\

> 2.  Which of the following potential back doors is controlled for by comparing the treated group to a control group?

b. There may be events affecting everyone that would change the outcome from before-treatment to after-treatment anyway\

> 3. Consider a treatment and control group. Looking only at the pre-treatment period, they have exactly the same outcomes (zero gap between them in each period).

**a. Despite having exactly the same outcomes pre-treatment, it happens to be the case that parallel trends is violated for these two groups. How is this possible? Explain what it means for parallel trends to be violated in this case, or give an example of how it could be violated.** \
This could be violated if there is an instance where at a later time in the analysis there is a gap, even though no treatment is applied. This would mean that the parallel trends assumption is violated because even with no treatment the gap did not stay the same after time passed. Instead, there is something else that might be effecting the gap besides the treatment that we will not be able to explain and then we will mistakenly attribute its effect to the treatment.\
**b. If we estimate the causal effect in this case using difference-in-differences, even though parallel trends is violated, how much would our effect be off by? (note you won't be able to give a specific number)** \
The effect would be off by however much the other unknown factor is effecting the difference.\

> 4.  Consider the below graph showing the average outcome for treated and control groups in the leadup to treatment (indicated by the dashed line), and also after treatment.

**a. Based on the prior trend, does it seem likely that parallel trends holds in this instance?**\
No, the lines do not seem to be following similar trends. \
**b. If we estimate difference-in-differences anyway, are we likely to overestimate the actual causal effect, underestimate it, or get it right on average?**\
Based on the city example, since this trend was already moving upward it seems like we will likely underestimate the actual causal effect. I think this is because the trends are converging.\

> 5. In mid-2020, during the COVID-19 pandemic, different countries pursued different courses of action. Some locked down fully, imposing harsh penalties to most people for leaving the house outside certain proscribed times. Some were looser and only suggested staying at home, and some had hardly any restrictions at all. You notice that COVID rates tend to spike dramatically in different countries at seemingly-random times, and want to know if certain restrictions helped.\
From March through May 2020, US and Canada COVID case rates followed similar trends (US rates were higher, but the trends were similar). You want to look at the effect of COVID restrictions enacted in Canada in late May 2020 on case rates. Is DID, with the US as a control group, a good way to estimate this effect? If not, what concerns would you have about this research design?

At first glance, this design seems like it could be a good way to estimate the effect because the lines have similar trends. However, I am worried if there are other back-doors that are not being considered. For example, would things like Canada having universal health care or differences in adhering to COVID policies within each country matter in a way that makes the effects have extra noise than we are assuming? \

> 6.  Consider the below table of mean outcomes, and calculate the difference-in-difference effect of treatment. Write out the equation you used to calculate it (i.e. show how the four numbers in the table are combined to get the estimate).


|           | before | after |
|-----------|:------:|:-----:|
| treated   |    5   |   9   |
| untreated |    6   |  7.5  |

```{r}
# (treated2-treated1) - (untreated2-untreated1)
(9-5)-(7.5-6)
```
The DID effect of treatment is 2.5.\

## How is it Performed?\
       
> 1. You are planning to estimate whether voter-protection laws increase voter turnout. You note that, in 2015, a lot of new voter-protection laws were enacted in some provinces but not in others. Conveniently, no new laws were enacted in 2012, 2014, or 2016, so you decide to use 2012 and 2014 as your “before” periods and 2016 as “after”. 

**a. Which of the following best describes what you’d want to regress state-and-year level “voter turnout” measures on?**\

iv. A set of fixed effects for state, and for year, and an interaction between “is 2016” and “is a treated state”.\

**b. Unless you chose the final option in the previous question, specify which coefficient in that regression would give you the DID estimate.**\
The coefficient from the interaction term between "is 2016" (post) and "is a treated state"(treatment) will give us the DID estimate.\

> 2. You are looking at a difference-in-difference design to estimate the effect of providing laptops to school children on their test scores. Look at the below regression output, in which “Treated” is an indicator that the school received laptops in 2008 as part of a new program (the untreated group did not receive any laptops until years after the sample window for this study ended), and “After” is an indicator for being after the year 2008.

**Using the table, fill in the blanks in the sentence "Assuming that _________, the effect of laptops on test scores was ______, and this effect (was/was not) statistically significant at the 95% level."**\

|                 |  Test Scores  |
|----------------:|:-------------:|
|     (Intercept) |    80.342***  |
|                 |    (0.501)    |
|           After |    3.369***   |
|                 |    (0.696)    |
|         Treated |    4.116***   |
|                 |    (0.718)    |
| After × Treated |    5.034***   |
|                 |    (0.993)    |
|       Num. Obs. |      1523     |
|           $R^2$ |     0.188     |

Standard errors in parentheses.
+ p < 0.1, * p < 0.05, ** p < 0.01, *** p < 0.001
```{r}
# use the interaction term to calculate the t-statistic
5.034/0.993

```
**Assuming that the parallel trends assumption holds true, the effect of laptops on test scores was 5.034, and this effect was statistically significant at the 95% level.**\

> 3. A standard “prior trends” test might estimate a regression using the model $Y= \beta_0+\beta_1t+\beta_2Treated+\beta_3 t×Treated+\epsilon$ (only using data from before-treatment), where t is a time variable, Treated is an indicator for being in the treated group, and Y is an outcome variable, and look for a large/significant estimate of $\beta_3$. Explain why this test is performed, and specifically what it shows.

The prior trends tests is performed so that we can compare the trends of the untreated and treated groups up to the moment of treatment. This helps us to show how different the trends are and helps us make the assumption of what we think the trends will look like (hopefully similar) after the treatment if it had not occurred. This allows us to have a reason to compare the two groups chosen, based on the parallel trends assumption.\

> 4. Consider the below graph with estimates from a dynamic difference-in-differences model for a treatment that occurs between periods 4 and 5, with 95% confidence intervals shown.

**a.What about this graph might make us concerned about our identification assumptions?**\
The confidence interval in period one is largely above zero, while in the other groups it is not. I wonder why the effect seems so inconsistent across these first three pre-treatment periods.\
**b.Ignoring any concerns we have, what would we say is the effect of treatment on Y in this case? (note the height of the line in period 5 is about 3, in period 6 is about 1, and in period 7 is about .5).**\
There is an effect that declines over time.\

> 5. Chapter 18.2.5 points out a problem with two-way fixed effects in cases where treatment is not all assigned at the same time, but rather different groups get treated at different times (a “rollout” design). In these designs, two-way fixed effects treats “already-treated” units, who were treated in earlier periods, as “control” units, as though they hadn’t gotten treated at all.\
However, there’s nothing theoretically wrong about using an already-treated unit as a control; the DID assumptions don’t require that the control group be untreated, just that the gap between treated and control doesn’t change when the treated group’s treatment goes into effect. Why are we so concerned, then, about using an already-treated group as a control? You can answer generally, or use as an example a DID with only two groups – an already-treated group and a newly-treated group. (hint: to do the example, try assuming the treatment only has an effect for the single period after treatment, and the already-treated group is treated exactly one period before the treated group)

I would be concerned with the fact that effects can change past the moment of treatment or may actually occur past the exact moment of treatment. This seems like it would impact the slope and violate our parallel trends assumption.\

# Coding Questions\ 


> 1.  In this assignment we will be walking through a very simple application of difference-in-differences that comes from Peter Nencka. In particular, it seemed that the beginning of the COVID-19 pandemic led to a brief craze for homemade sourdough bread, as people had to stay home, and stores were out of yeast (sourdough can be made at home using yeast from the air and does not require store-bought yeast). We will be estimating whether COVID lockdowns actually increased interest in sourdough bread. \
We will be measuring interest in sourdough bread using Google Trends data in the USA. Google Trends tracks the popularity of different search terms over time. We will be comparing the popularity of the search term "sourdough" against the control groups: the search terms "cereal," "soup," and "sandwich," the popularity of which we suspect might not have been meaningfully affected by COVID lockdowns.

Load the data set `sourdough_trends.csv` and look through the data. In R
or Python, save the dataset as `sr`.
```{r}
library(tidyverse)
library(lubridate)
sr <- read_csv("/Users/allysontcameron/soc_723_stats/Data/sourdough_trends.csv")
sr <- sr %>% 
  select(date, hits, keyword) %>% 
  mutate(date = ymd(date))

# check date is a date
class(sr$date)
```

> 2.  Make a line graph with `date` on the x-axis and `hits` on the y-axis, with a separate line for each `keyword`. Also add a vertical line for the "start of the pandemic" which we'll decide for our purposes is March 15, 2020.

```{r}
library(ggplot2)
ggplot(sr, aes(x = date, y = hits, color = keyword)) + geom_line() + 
  theme_bw() + theme(axis.text.x=element_text(angle=60, hjust=1)) +
  scale_x_date(name = "Date", breaks= "1 month") + labs(title = "Popularity of Certain Search Terms during COVID") + ylab("Number of Searches") +
  geom_vline(xintercept = as.numeric(ymd("2020-03-15")), linetype = 2) +
  annotate(geom = "vline",
             x = ymd("2020-03-15"),
             xintercept = ymd("2020-03-15"),
             linetype = "dashed") +
    annotate(geom = "text",
             label = "start of the pandemic",
             x = ymd("2020-04-13"),
             size = 3.5,
             y = 90,
             vjust = 1) 
```

> 3.  Looking at your graph from problem 2, comment on (a) whether it looks like the lockdown had an effect on the popularity of sourdough, (b) the shape that effect takes (i.e. is it a permanent increase in popularity? Temporary?), (c) whether you might be concerned about any of the control groups we've chosen.

a) its hard for me to make this comparison against soup, but comparing against sandwich and cereal it seems like it did have an effect.\
b) the increase was only temporary, lasting from the start of the pandemic to around the summer months (end of May to beginning of June).\
c) I am concerned with the control group soup which seems to have a different pre-treatment trend than sourdough. \

> 4.  Create a "Treated" indicator that's equal to 1 for sourdough and 0 otherwise (or True/False, either way). Do a test of whether the prior trends (keeping March 15 as the "treatment date") differ between the treated and control groups, using a linear trend and doing a statistical significance test at the 95% level. Then, if you were concerned about any of the control groups in question 3c, drop any you were concerned about (and keep them dropped for the rest of the assignment) and rerun the test.

```{r}
library(fixest)
library(modelsummary)
sr <- sr %>% 
  mutate(treated = ifelse(keyword == "sourdough", 1L, 0L))

# make dataset with prior trends
prior_sr <- sr %>%
  filter(date < "2020-03-15")

m1 <- lm(hits ~ date + keyword + date*keyword, data = prior_sr)

# make dataset without soup
prior_sr2 <- prior_sr %>% 
  filter(keyword != "soup")

m2 <- lm(hits ~ date + keyword + date*keyword, data = prior_sr2)

modelsummary(m1, stars = TRUE)
modelsummary(m2, stars = TRUE)

# create new data frame without soup
sr <- sr %>% 
  filter(keyword != "soup")


```
![model summary 1](/Users/allysontcameron/soc_723_stats/TE/images /m1.png)

![model summary 2](/Users/allysontcameron/soc_723_stats/TE/images /m2.png)

**Write a line commenting on whether you can reject equal prior trends in your model(s).**\

Since the interaction we care about (date*sourdough) is not meaningfully different in either model, we cannot reject the assumption that the there are equal prior trends. \

> 5.  Create a `month` variable by shifting the `date` variable back 15 days (so that the treatment day is the first day of the month) and then taking the month of the resulting date. Also create an `After` variable equal to 1/0 (or True/False) if the date is March 15 or afterwards. \
Then, take a look at the values of `month` you get and how they line up with `date`, and subtract a number from `month` so that the last period just before treatment (Feb 16-Mar 14) is 0. (Also, change the Jan 1-14 month so it's one less than the Jan 15-Feb 14 month).\
Then, use two-way fixed effects to estimate the difference-in-difference estimate of the effect of lockdown on sourdough popularity with `keyword` and `month` fixed effects, and standard errors clustered at the `keyword` level.

```{r}

#create month variable 
sr <- sr %>% 
  mutate(month = month(date - days(14)))

#create 'after' variable
sr <- sr %>% 
  mutate(after = if_else(date >= "2020-03-15", 1L, 0L ))

# need to subtract 2 since the month right before is listed as 2
sr <- sr %>% 
  mutate(month = month - 02)

# fixing other month variables
sr <- sr %>% 
  mutate(month = if_else(month > 9, -2, month))

# the model
m3 <- feols(hits ~ after*treated | keyword + month, data = sr)

# summary
modelsummary(m3, stars = TRUE)

```
![](/Users/allysontcameron/soc_723_stats/TE/images /m3.png)

>6.  Now, let's allow the effect to be dynamic over time. Estimate a difference-in-difference model allowing the effect to differ by month (using `month = 0` as a reference period), with standard errors clustered at the keyword level, and show the results.

```{r}
# sourdough variable
sr <- sr %>% 
  mutate(sourdough = keyword == "sourdough")

#specify the model
m4 <- feols(hits ~ i(month, sourdough, ref = 0) | keyword + month, data = sr)

#show the results
msummary(m4, stars = TRUE)
```

>7.  Make a graph demonstrating the results of your dynamic difference-in-differences model. Describe both what the effect looks like and also whether this graph gives you any concerns about prior trends violations.

```{r}
coefplot(m4)
```
![](/Users/allysontcameron/soc_723_stats/TE/images /final graph.png)

We see a graph that looks a lot like the graph from question 4 in the above section. However, luckily the pre-treatment time periods look more stable and centered around 0, which makes me less concerned with prior trend violations. Also, after the treatment occurs (first place would be 1) we see the spike and then the values decrease, which is what we would expect based on what we saw in our above graph (from question 2), we know that the effect does dissipate. \