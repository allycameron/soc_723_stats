---
title: "Matching and Weighting in R Exercises"
author: "Allyson Cameron"
date: "03-09-2023"
output:
  html_document:
    df_print: paged
subtitle: Statistical Horizons
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Instructions

For these exercises, we are going to use one of the versions of the "Lalonde data," which is used in almost every paper on matching.\

To make sure you have everything loaded that you need, put the following commands at the top of your Rmd file. If you're using the tidyverse commands, make sure to put `tidyverse` last, or other commands might mask `dplyr::select`.\

```{r}
library(survey)                
library(broom)
library(cobalt)
library(MatchIt)
library(WeightIt)
library(tidyverse)
library(rethinking)
theme_set(theme_minimal()) # optional

load("exercise_data.Rdata")

```


Before starting the exercises, you may want to consider a few things that will make your life easier:

* add a factor version of the treatment to the data frame for easy plotting\

```{r}
d <- d %>% 
  mutate(treat_fact = as.factor(treat))
d_exper <- d_exper %>% 
  mutate(treat_fact = as.factor(treat))
```

*create formula objects that contain the propensity score (or matching) models with and without
quadratic terms\
```{r}
# not going to do the objects
# but will create function like in class for visualizing balance
love_plot <- function(x) {
  love.plot(x, 
            binary = "std" ,
            stats = c("m", "ks") ,
            thresholds = c(.1, .05),
            var.order = "adjusted",
            abs = TRUE)
}
```

## Exercises\

### QUESTION 1\
> Use the experimental data to estimate the effect of the job training treatment. How much does it appear to affect 1978 income? Now look at the observational data (for all exercises from now on). How large is the raw difference in 1978 income between the treatment group and the PSID comparison group?

```{r}
m1 <- lm(re78 ~ treat_fact, data = d_exper) %>% 
  tidy( ,conf.int = TRUE)

m1

m1_raw <- lm(re78 ~ treat_fact, data = d) %>% 
  tidy( ,conf.int = TRUE)

m1_raw

# 0.8863038	 <- m1 estimate of re78
# -16.54134 <- m1_raw estimate of re78

```

The treatment effect estimate of the job training for the experimental data is $886, with 95% confidence interval of a decrease in 40.5 dollars to an increase in 1,813 dollars. \

The treatment effect (naive) estimate of the job training for the actual data is that the job training decreases income by $16,541 with a 95% confidence interval of a decrease of 14,721 dollars to 18,361 dollars. \

### QUESTION 2\
> 2. Try to estimate the effect of the treatment using regression. What does regression say the effect of the program is?

```{r}
m2 <- lm(re78 ~ treat_fact + age + educ + black + hisp + married + nodegr + re74 + 
           re75 + u74 + u75 + I(age^2) + I(educ^2) + I(re74^2) + I(re75^2), data = d) %>% 
  tidy( ,conf.int = TRUE)

m2
```
The model after regression estimates that the average treatment effect will be a decrease in $1,949, or 95% confidence interval of a decrease of 233 dollars or 3,665 dollars. We are still really far off from the experimental estimate. \

### QUESTION 3\
> 3. Begin by exact matching on all the dummy variables. How many treated cases cannot be matched? What is the (FS)ATT estimate?

```{r}
# create matches
match_out3 <- matchit(treat_fact ~ black + hisp + married + nodegr + u74 + u75, 
                      data = d,
                      method = "exact")

# lets see how many cases are dropped
summary(match_out3)
# get the data and weights
match_data3 <- match.data(match_out3)
# now lets do the (FS)ATT using the weights from the match_out3
lm(re78 ~ treat_fact, data = match_data3, weight = weights) %>% 
  tidy( ,conf.int = TRUE)

```
131 cases are dropped. Of these cases that are dropped, 10 treated cases are dropped.\

The (FS)ATT is that income will decrease by $2,386, with a 95% confidence interval of a decrease of 1,078 dollars to 3,694 dollars. This is still way off from the experimental data's estimate. \

### QUESTION 4\
> 4. Use the observational data to estimate each case's propensity to receive treatment using `glm()`. Use a logistic regression with quadratic terms for age, education, 1974 income, and 1975 income. Spend a few moments thinking about what this model says. If you are familiar with plotting in R, look at the density plots of the p-score for treated and untreated groups. (If not, you can move on. We'll do the same thing using `bal.plot()` in a bit.)

```{r}
psmod4 <- glm(treat_fact ~ age + educ + black + hisp + married + nodegr + re74 + 
           re75 + u74 + u75 + I(age^2) + I(educ^2) + I(re74^2) + I(re75^2), 
           data = d,
           family = binomial) 

## overlap in probabilities
augment(psmod4, type.predict = "response") %>%  
  ggplot(aes(.fitted, fill = treat_fact)) + 
  geom_density(alpha = 0.4) + 
  scale_x_log10()

## overlap in log-odds
augment(psmod4, type.predict = "link") %>% 
  ggplot(aes(.fitted, fill = treat_fact)) + 
  geom_density(alpha = 1/4) + 
  scale_x_continuous()
```

Looking at both of these graphs, they don't look very "matched", they aren't overlapping either time. Interesting.\

### QUESTION 5\
>5. Conduct 1:1 nearest-neighbor matching on the log odds of the propensity score. Use `bal.plot()` to compare the overall propensity score distributions. Do once without replacement and once with replacement. Why do you think there's a difference? Try to figure it out. Estimate the ATT for each assumption (i.e., with or without replacement). If you achieve good overall balance on the propensity score, try checking individual covariate balance using `love.plot()`. 

```{r}

# without replacement
ps_out5 <- matchit(treat_fact ~ age + educ + black + hisp + married + nodegr + re74 + 
           re75 + u74 + u75 + I(age^2) + I(educ^2) + I(re74^2) + I(re75^2), 
                 data = d,
                 replace = FALSE, 
                 method = "nearest")
# get the data to see the estimate
ps_data5 <- match.data(ps_out5)
# run regression with ps matching without replacement
lm(re78 ~ treat_fact, data = ps_data5, weight = weights) %>% 
  tidy( ,conf.int = TRUE)

# with replacement
ps_out5_r <- matchit(treat_fact ~ age + educ + black + hisp + married + nodegr + re74 + 
           re75 + u74 + u75 + I(age^2) + I(educ^2) + I(re74^2) + I(re75^2), 
                 data = d,
                 replace = TRUE, 
                 method = "nearest")
# get the data to see the estimate
ps_data5_r <- match.data(ps_out5_r)
# run regression with ps matching with replacement
lm(re78 ~ treat_fact, data = ps_data5_r, weight = weights) %>% 
  tidy( ,conf.int = TRUE)

# visualizing both

bal.plot(ps_out5, 
         which = "both", 
         type = "density", 
         var.name = "distance") +
  theme(legend.position = "top")

bal.plot(ps_out5_r, 
         which = "both", 
         type = "density", 
         var.name = "distance") +
  theme(legend.position = "top")

# checking love plot only on replace since this one has good balance
love_plot(ps_out5_r)

```

So, before running the `bal.plot()` function, just looking at the estimates we can see that once we use the replacement version of matching we are getting at least getting an estimate now that shows there is a possibility of an increase in income instead of just a decrease in income (without replacement: decrease 5,258 to 2,340 dollars; with replacement: decrease 1,609 dollars to increase of 1,623 dollars). \

Now, looking at the `bal.plot()` I see that without replacement they do not seem to be congruent; however, with the replacement the distribution is **WAY MORE** similar. However, when looking at the `love.plot()`, we see that there is actually not as much balance as we would expect from thhe distribution when looking at the KS (more conservative) measure. \

### QUESTION 6\
>6. Estimate propensity scores and ATT weights using `weightit()`. Ignore the warning you get. We'll discuss that more in class. Estimate the ATT. Check for covariate balance.

```{r}
# estimating weights
W6 <- weightit(treat_fact ~ age + educ + black + hisp + married + nodegr + re74 + 
           re75 + u74 + u75 + I(age^2) + I(educ^2) + I(re74^2) + I(re75^2), 
               data = d, 
               method = "ps", 
               s.weights = NULL,
               estimand = "ATT")

# checking for balance using love_plot
love_plot(W6)
```

Well, looking at the output for the covariate balances, we see there are some alarming results. They are not very balanced. However, let's see what the estimates would be of income using this method.
```{r}
lm(re78 ~ treat_fact, data = d, weights = W6$weights) %>%  
  tidy( ,conf.int = TRUE)
```

This estimate looks way better than anything we've see so far. It looks pretty close to the 95% confidence interval of the experimental data. Here the confidence interval for the TE is an increase in income from 613 dollars to 1,665 dollars. In the experimental data the 95% CI was a decrease of 40.5 dollars to an increase in 1,813 dollars. We're in the range, but it doesn't account for the proposed decrease that the experimental data does include. \

### QUESTION 7\
>7. Now do the same as above using covariate balancing propensity scores.

```{r}
# how to use in weights
CB7 <- weightit(treat_fact ~ age + educ + black + hisp + married + nodegr + re74 + 
           re75 + u74 + u75 + I(age^2) + I(educ^2) + I(re74^2) + I(re75^2), 
               data = d, 
               method = "CBPS", 
               over = TRUE,
               estimand = "ATT")

# visualizing balance

love_plot(CB7)

```

Now, the balance output looks much better, though not good enough. Especially when looking at the KS statistics. However, again, let's calculate the estimates. 

```{r}
# getting ATT
lm(re78 ~ treat_fact, data = d, weights = CB7$weights) %>%  
  tidy( ,conf.int = TRUE)
```

These values look slightly better, it accounts for the increase and decrease with a 95% CI of decreasing 507 dollars to an increase in 646 dollars. \

### QUESTION 8\
>8. Try Mahalanobis distance matching with replacement and using a caliper of .1. How many unique control cases get matched?

```{r}
m_match_out <- matchit(treat_fact ~ age + educ + black + hisp + married + 
                         nodegr + re74 + re75 + u74 + u75,
                       data = d,
                       distance = "glm",
                       caliper = .1,
                       replace = TRUE, 
                       mahvars = ~ age + educ + black + hisp + married + 
                         nodegr + re74 + re75 + u74 + u75, 
                        estimand = "ATT")
# trying to see dropped cases
summary(m_match_out)
# looking at balance
love_plot(m_match_out)

m_data8 <- match.data(m_match_out)

lm(re78 ~ treat_fact, data = m_data8, weight = weights) %>% 
  tidy( ,conf.int = TRUE)

```
This time around, we don't have any treated cases that are dropped. \

Although the covariates seem balanced with the mean differences, looking at the KS statistics output we see that they are actually even more imbalanced than we originally thought. The income estimates here encompass the experimental data but are still pretty bad (decrease in 1,313 dollars to an increase in 2,001 dollars).\

### QUESTION 9\
>9. Use entropy balancing to balance treatment and control. Confirm that you've achieved balance on the means and the variances of the covariates.

```{r}
e_output <- weightit(treat_fact ~ age + educ + black + hisp + married + 
                         nodegr + re74 + re75 + u74 + u75, 
                   data = d, 
                   method = "ebal", 
                   moments = 3, 
                   estimand = "ATT")
love_plot(e_output)
```

While there is balance here for the mean differences, again, looking at the KS statistics we see that the covariates are not ballanced even once adjusted. Let's look at the estimates here. 

```{r}
lm(re78 ~ treat_fact, data = d, weight = e_output$weights) %>% 
  tidy( ,conf.int = TRUE)
```
This looks the MOST similar to the experimental data. The confidence interval is a decrease in 341 dollars and an increase in 1,481 dollars (compared to the experimental data estimates of an income decrease of 40.5 dollars to an increase in 1,813 dollars). 

### QUESTION 10\
>10. Now revisit questions 3 and 5-9. This time, instead of just using simple regressions to estimate the ATT, estimate full outcome regressions using the dataset you "preprocesssed" with matching or weighting. How does this affect the estimates?

```{r}
# for exact matching
robust_match <- lm(re78 ~ treat_fact + age + educ + black + hisp + married 
                        + nodegr + re74 + re75 + u74 + u75 + I(age^2) + 
                          I(educ^2) + I(re74^2) + I(re75^2), data = match_data3,
                   weight = weights)  %>% 
  tidy( ,conf.int = TRUE)
# for propensity score matching
robust_ps <- lm(re78 ~ treat_fact + age + educ + black + hisp + married 
                        + nodegr + re74 + re75 + u74 + u75 + I(age^2) + 
                          I(educ^2) + I(re74^2) + I(re75^2), data = ps_data5_r, 
                weight = weights) %>% 
  tidy( ,conf.int = TRUE)
# for propensity score weighing
robust_W6 <- lm(re78 ~ treat_fact + age + educ + black + hisp + married 
                        + nodegr + re74 + re75 + u74 + u75 + I(age^2) + 
                          I(educ^2) + I(re74^2) + I(re75^2), data = d, 
                weights = W6$weights) %>% 
  tidy( ,conf.int = TRUE)
# for CBPS
robust_CB7 <- lm(re78 ~ treat_fact + age + educ + black + hisp + married 
                        + nodegr + re74 + re75 + u74 + u75 + I(age^2) + 
                          I(educ^2) + I(re74^2) + I(re75^2), data = d, 
                 weights = CB7$weights) %>% 
  tidy( ,conf.int = TRUE)
# for Mahalanobis
robust_m_match <- lm(re78 ~ treat_fact + age + educ + black + hisp + married 
                        + nodegr + re74 + re75 + u74 + u75 + I(age^2) + 
                          I(educ^2) + I(re74^2) + I(re75^2), data = m_data8, 
                     weight = weights) %>% 
  tidy( ,conf.int = TRUE)
# for entropy balancing
robust_e <- lm(re78 ~ treat_fact + age + educ + black + hisp + married 
                        + nodegr + re74 + re75 + u74 + u75 + I(age^2) + 
                          I(educ^2) + I(re74^2) + I(re75^2), data = d, 
               weight = e_output$weights) %>% 
  tidy( ,conf.int = TRUE)
```
So, I don't know how to plot all of these things so I am just going to compare them this way. \

**FOR REFERENCE:The treatment effect estimate of the job training for the experimental data is $886, with 95% confidence interval of a decrease in 40.5 dollars to an increase in 1,813 dollars.** \

robust entropy balancing model: The TE estimate of income is 95% CI of a decrease by 144 dollars to an increase in 1,283 dollars. (seems pretty good)\
robust Mahalanobis model: The TE estimate of income is 95% CI of a decrease in 1,387 dollars to an increase in 1,857 dollars (not so good)\
robust CBPS model: The TE estimate of income is 95% CI of a decrease in 309 dollars to an increase in 746 dollars (not terrible, but missing a lot on the higher end)\
robust propensity score weighting model: The TE estimate of income is 95% CI of a an increase in 154 dollars to 1,157 dollars. (again, not terrible but missing that the experimental data accounts for a decrease)\
robust propensity score matching model: The TE estimate of income is 95% CI of a decrease in 1,350 dollars to an increase in 1,785 dollars. (pretty bad, just a wide confidence interval).
robust exact matching model:  The TE estimate of income is 95% CI of a decrease in 154 dollars to an increase in 1,538 dollars. (not too bad actually)\

### QUESTION 11\
> 11. **Bonus:** implement a bootstrap of your preferred estimate. What is the bootstrapped standard error?

SKIP
