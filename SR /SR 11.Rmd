---
title: "SR 11"
output: html_document
date: "2023-01-24"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Easy Questions\

**11E1. If an event has probability 0.35, what are the log-odds of this event?**\
```{r}
library(rethinking)
logit(0.35)
```

The log-odds are -0.62.\

**11E2. If an event has log-odds 3.2, what is the probability of this event?**\

```{r}
inv_logit(3.2)
```

The probability is 0.96.\

**11E3. Suppose that a coefficient in a logistic regression has value 1.7. What does this imply about the proportional change in odds of the outcome?** \

```{r}
exp(1.7)
```
1.7 represents the log odds, so to get the odds can be shown be exponentiating the log-odds. Each time the predictor is increased by one-unit, the odds will multiplicatively increase by 5.473947. \

**11E4. Why do Poisson regressions sometimes require the use of an offset? Provide an example.**\

Poisson distributions assume that the rate of events is constant over time, so...when the exposure varies across observations (which can naturally happened from  lengths of observation, area of sampling, or intensity of sampling varying) then you will need to add an offset term to the linear model. [PAGE 357]\

```{r}
# compute example tomorrow.... or later today
```


# Medium Questions\

**11M1. As explained in the chapter, binomial data can be organized in aggregated and dis-aggregated forms, without any impact on inference. But the likelihood of the data does change when the data are converted between the two formats. Can you explain why?**\

[need answer]

**11M2. If a coefficient in a Poisson regression has value 1.7, what does this imply about the change in the outcome?**\
```{r}
exp(1.7)
```
This one is a little bit harder. The change depends on the values of the other parameters. We will solve this like we did the other questions calculating the change in odds... so in a Poisson model, a 1.7 coefficient will lead to a proportional change of 5.473947 when the predictor variable increases by one unit. 
**11M3. Explain why the logit link is appropriate for a binomial generalized linear model.**\
In a  binomial model the continuous values from the model are translated to a probability space between 0 and 1. The logit link does this. 
**11M4. Explain why the log link is appropriate for a Poisson generalized linear model.**\
For the poisson model, we need to be able to place the continous values in a space that is from 0 to positive whole numbers. The log link function allows us to do this. 
**11M5. What would it imply to use a logit link for the mean of a Poisson generalized linear model? Can you think of a real research problem for which this would make sense?**\

This would mean that we are using a model where the know the maximum count (at most one event within each interval). However, in this case that is not the beauty of Poisson's function (it is able to be used when we don't know the maximum), so instead it would mke more since to use a binomial model. [RECHECK THIS IDK]

**11M6. State the constraints for which the binomial and Poisson distributions have maximum entropy. Are the constraints different at all for binomial and Poisson? Why or why not?**\

Both have the same constraints:

1. constant probability of event across all trials
2. discrete outcomes that are binary. 

They are the same because Poisson models are a type of binomial model. 
**11M7. Use quap to construct a quadratic approximate posterior distribution for the chimpanzee model that includes a unique intercept for each actor, m11.4 (page 330). Compare the quadratic approximation to the posterior distribution produced instead from MCMC. Can you explain both the differences and the similarities between the approximate and the MCMC distributions? Relax the prior on the actor intercepts to Normal(0,10). Re-estimate the posterior using both ulam and quap. Do the differences increase or decrease? Why?**\
```{r}
library(tidyverse)
library(tidybayes.rethinking)
library(tidybayes)
# data
data(chimpanzees)
d <- chimpanzees
d <- d %>% 
  mutate(treatment = as.integer(1 + prosoc_left + 2 * condition)) %>% 
  select(pulled_left, treatment, actor)
  

# using ulam with original priors
m11.4 <- ulam(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) <- a[actor] + b[treatment],
    a[actor] ~ dnorm(0, 1.5),
    b[treatment] ~ dnorm(0, 0.5)
  ),
  data = d, chains = 4, log_lik = TRUE
)

precis(m11.4, 2)
# using quap with original priors

m11.4q <- quap(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) <- a[actor] + b[treatment],
    a[actor] ~ dnorm(0, 1.5),
    b[treatment] ~ dnorm(0, 0.5)
  ), data = d)

precis(m11.4q, 2)

# now the models with the relaxed prior. 

# ulam
m11.4_r <- ulam(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) <- a[actor] + b[treatment],
    a[actor] ~ dnorm(0, 10),
    b[treatment] ~ dnorm(0, 0.5)
  ),
  data = d, chains = 4, log_lik = TRUE
)

precis(m11.4_r,2)

# quap

m11.4q_r <- quap(
  alist(
    pulled_left ~ dbinom(1, p),
    logit(p) <- a[actor] + b[treatment],
    a[actor] ~ dnorm(0, 10),
    b[treatment] ~ dnorm(0, 0.5)
  ), data = d)

precis(m11.4q_r, 2)
```


All of the variables seem extremely similar. A[2] has a higher difference than other parameters.With the more relaxed prior, the difference between a[2] becomes even larger. I wonder if this difference has something to do with the fact that quap assumes the shape is normally distributed while ulam assumes no shape.  
**11M8. Revisit the data(Kline) islands example. This time drop Hawaii from the sample and refit the models. What changes do you observe?**\

```{r}

# get the data together
data(Kline)
k <- Kline %>% 
  mutate(P = log(population)) %>% 
  mutate(cid = ifelse(contact == "high", 2, 1)) %>% 
  mutate(T = total_tools) %>% 
  select(T,P, cid, culture)


# interaction model with Hawaii
m11.10H <- ulam(
   alist(
     T ~ dpois(lambda),
     log(lambda) <- a[cid] + b[cid] * P,
     a[cid] ~ dnorm(3, 0.5),
     b[cid] ~ dnorm(0, 0.2)
   ),
   data = k, chains = 4, log_lik = TRUE
 )
# without

d
k <- Kline %>% 
  mutate(P = log(population)) %>% 
  mutate(cid = ifelse(contact == "high", 2, 1)) %>% 
  mutate(T = total_tools) %>% 
  select(T,P, cid, culture)
m11.10 <- ulam(
   alist(
     T ~ dpois(lambda),
     log(lambda) <- a[cid] + b[cid] * P,
     a[cid] ~ dnorm(3, 0.5),
     b[cid] ~ dnorm(0, 0.2)
   ),
   data = dat, chains = 4, log_lik = TRUE
 )

```

