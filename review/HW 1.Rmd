---
title: "HW 1"
output: html_document
date: "2023-01-12"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Let's begin by loading the data in our usual way.

```{r}
library(tidyverse)

# read the file
twitch_data <- read_csv("../Data/twitchdata-update.csv")

# looking at the data
View(twitch_data)

# clean up names
library(janitor)
twitch_data <- clean_names(twitch_data)

# let's look at the new names
colnames(twitch_data)
```

# Question 1\

Part one of the question show the `average_viewers` and `followers` for five random streamers. \

```{r}
library(dplyr)
library(tidyverse)
# create tibble with sample of 5 streamers
set.seed(0112)
sample_data <- sample_n(twitch_data, 5) %>% 
  select(channel, average_viewers, followers )

sample_data
  
```
**What do you notice?** The first thing that I notice is that followers and average viewers do not seem to be as closely related as I would have expected. In all cases, it seems that each channel has a high number of followers (in my opinion) but this does not translate to a high number of views, and views seem to always be much lower than a channel's actual number of followers. \

Now, let's summarize these two variables. \

```{r}
summary(sample_data)
```
**Describe the results in a few words. Does anything capture your attention?** \
The viewers always seem to be much lower than the followers by a noticeable amount. This is interesting as I would have thought a higher percentage of followers would tune in to streams from the channels they follow. Additionally, there seem to be outliers associated with both (I say this because the max and min for both are a great distance away from the median).\

Now, lets visualize the data by creating a scatter plot. \
```{r}
library(ggplot2)

# lets create the scatter plot using ggplot
ggplot(twitch_data, mapping = aes(x = followers, y = average_viewers)) + 
  geom_point(alpha = 1) + labs(x = "Number of Followers", y = "Average Viewers", title = "Twitch Channels Average Viewers by Follower Count")

# create plot with logged values

ggplot(twitch_data, mapping = aes(x = followers, y = average_viewers)) + 
  geom_point(alpha = 1) + labs(x = "Number of Followers (Logged)", y = "Average Viewers (Logged)", title = "Twitch Channels Average Viewers by Follower Count") + scale_x_log10() + scale_y_log10()
```

I notice that most of the channels have a low number of followers and average viewers, and there are a few channels that have more followers but still a lower number of viewers and even fewer that have a small number of followers and a high number of viewers. What I find the most interesting is that there aren't any channels with a high number of followers and a high number of viewers! \

To try to fix this uneven distribution, we will transform the data by scaling with log. \

```{r}

# make the transformations
twitch_data <- twitch_data %>% 
  mutate(log_viewers = log10(average_viewers), 
         log_followers = log10(followers))

# create new scatter plot

ggplot(twitch_data, mapping = aes(x = log_followers, y = log_viewers)) + 
  geom_point(alpha = 1) + labs(x = "Number of Followers (Logged)", y = "Average Viewers (Logged)", title = "Twitch Channels Average Viewers by Follower Count")


```

**What do you see now? How does the relationship look like?** Now, the points are all packed within the same plane, and it seems like there are less outliers at least by the visualization, and there points that seem like outliers look closer together.  This helps me to see that there could be evidence for a positive linear relationship. \


# Question 2 \

Based on this, let's run a linear regression using `lm()`.\

```{r}
# let's log all of the raw data now..

twitch_data <- twitch_data %>% 
  mutate(log_viewers = log10(average_viewers), 
         log_followers = log10(followers))

fit1 <- lm(log_viewers ~ log_followers, data = twitch_data)
fit1
```


Now, let's look at another way to get a summary of our model.\

```{r}
library(broom)
tidy(fit1)
```

Now, let's interpret our coefficient from the logged followers. \

```{r}
# let's do the math to interpret our logged inputs. 
1.1^{0.6} 
```

$$1.1^{0.6} = 1.058853$$

For each 10% increase in followers, the model expects a a 1.06% increase in the average number of viewers. \

# Question 3\

Now, let's look at our line of best fit and check the residuals.\

```{r}
library(broom)

pred_data <- augment(fit1)

# glimpse our new data 
glimpse(pred_data)
```
Now, lets visualize the data. \

```{r}
pred_data %>% 
  ggplot(aes(x = log_followers, 
             y = log_viewers)) +
  geom_jitter(alpha = 0.4) + 
  geom_line(aes(x = log_followers, 
                y = .fitted), 
            col = "orange") + 
  theme_minimal() +
  labs(subtitle = "Fitted Model and Raw Data", 
       title = "Followers & Average Viewership", 
       x = "log(followers)", 
       y = "log(viewers)")
```

**Do you think our model describes the relationship well?** While the points on the lower end of the followers does not seem to be well represented by the line, the overall relationship of the points seem to be well represented by the line. I say this because the line seems to generally split the data in half which seems like a good sign. However, knowing the residuals would be most helpful to answer this question. \

```{r}
pred_data <- pred_data %>% 
  mutate(squared_res = .resid^2)

pred_data %>% 
  ggplot(aes(x = log_followers, 
             y = squared_res)) +
  geom_jitter(alpha = 0.4) + 
  theme_minimal() +
  labs(title = "Resideuals and Followers", 
       x = "log(followers)", 
       y = "Squared Residuals")
```

**What do you see? Are there any big residuals? Do they happen often in a particular range of our x-variable?**\
I see that most of the points are centered around 0, which is a good sign. However, there are some points that have bigger residuals. I squared the values so that I am only working with positive values. The biggest area where there is a spike in the values of the residuals is between log(followers) at 5 and 6. However, I think the smaller residuals are fine. The two around 2.5 worry me but since there are only two (between 5.5 and 6) I believe this is still okay? \

# Question 4 \

Now we will look at a regression using one categorical variable to predict one continuous variable. We will use `language` as the predictor and `average_viewers` as the dependent variable.\

```{r}
# look at the raw data
question_4 <- twitch_data %>% 
  select(channel, average_viewers, language )

glimpse(question_4)

# look at the summary
q4_2 <- question_4 %>% group_by(language) %>% 
  summarise(sum_viewers = mean(average_viewers)) %>% 
  arrange(desc(sum_viewers))

q4_2

```
This time around, I did the summary differently. I grouped by language and found the average views by language. Then, I reordered them from greatest to least. I see here that on average, Russian channels actually had the highest viewers, not English. This is surprising to me, but probably because I only speak English. \

```{r}
# plot the variables
ggplot(question_4, mapping = aes(x = language, y = log(average_viewers))) + 
  geom_boxplot() + theme(axis.text.x = element_text(angle = 90)) + 
  labs(title = "Average viewers by Language", x = "Language", 
       y = "Average Viewers")
```

I struggled with decided how to plot the raw data. I decided to create a boxplot since we have a categorical variable and a continuous variable. I logged the views so that the boxplot is easier to read. Looking at the visualization it makes sense as to why Russia comes in higher, the minimum viewership for Russian channels is a lot higher than the minimum viewership for English channels.\

# Question 5\
```{r}
library(moderndive)
twitch_data <- twitch_data %>% 
  mutate(language = as.factor(language), 
         language = relevel(language, ref = "English"))

fit2 <- lm(log_viewers ~ language, data = twitch_data)
fit3 <- lm(average_viewers ~ language, data = twitch_data)

# these do the same thing pretty much, the second just provides more info
tidy(fit2)
get_regression_table(fit2)

# for interpretation
get_regression_table(fit3)

```

**Interpret the results.** Since there are a lot of coefficients here I will try to interpret a few of them (using the regression table, I ended up going back and creating the model with viewers logged, but interpreted the results while they were in their normal state.\

Let's try to interpret a few of these values. I know that English is the reference category which means that it's mean is represented by the intercept. (I need more instruction on how to interpret logged results. I tried exponentiating (with `exp()` and using the trick you taught us with 1.1^{})  and the values were not as similar to the averages I found in the summary, but that is weird to me since with the original data everything seems to check out). So this interpretation will be with a new model called `fit3` which will keep the linear regression without the logged viewers). \

I think that English, the reference category is the intercept meaning that there is on average 5112 viewers for English channels. So, looking at Arabic for example, the average viewership for these channels is 5112.81 + 569.39 = 5682.2, 569.39 more viewers than English channels. Let's look at Greek-speaking channels. The average viewership for these channels is 5112.81 - 3151.81 = 1961 average viewers. If we look back at our tibble showing the raw data numbers, these numbers make sense. \

```{r}
# Now for the prediction
pred_data2 <- broom::augment(fit2, se_fit = TRUE) %>%  
  distinct(language, .fitted, .se.fit) %>% 
  mutate(lower = .fitted + qnorm(0.025) * .se.fit,
         upper = .fitted + qnorm(0.975) * .se.fit)
# glimpse our new data 
glimpse(pred_data2)
  
  ggplot(twitch_data, aes(log_viewers, language)) + 
  geom_jitter(color = "grey") +
  geom_pointrange(data = pred_data2, mapping = aes(x = .fitted, xmin = lower,
                                                   xmax = upper))  + 
  labs(title = paste0("Raw Data with point ranges of the fitted values from", 
       " predicted data"), x = "log(Average Viewers)",
       y = "Language of Channel")
```

**How is my prediction doing?** Based on these few I calculated above, the prediction seem to be spot on with the raw data. However, let's look at the residuals. 

# Question 6\

Now, let's look at the residuals. 

```{r}
res_plot <- augment(fit2) 
res_plot

# trying to make residual plot, not complete sure if I interpret correctly. 
ggplot(res_plot, aes(x = language, y = .resid)) + geom_point() + coord_flip() +
  labs(y = "Residuals", x = "Languages")
```

Here is me trying to plot the residuals for each language. I see that English had a pretty far spread from around 0. Most of the other languages have a tighter grouping around 0. I also see that Japanese and Russian have some pretty large value residuals. Other, Slovak, Swedish, and Finnish seem to have been predicted the best. 