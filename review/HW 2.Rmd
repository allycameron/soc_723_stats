---
title: "HW 2"
output:
  pdf_document: default
  html_document: default
date: "2023-01-12"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Let's begin by loading in the data. 

```{r}
library(tidyverse)
# Set our ggplot theme from the outset
theme_set(theme_light())
# Read in the data 
gender_employment <- read_csv("../Data/gender_employment.csv")

# Glimpse at the data 
glimpse(gender_employment)

#center year
unique(gender_employment$year)

gender_employment <- gender_employment %>% 
  mutate(year = year-2013)
```

Now lets visualize the data in respect to the trend we will be looking at. 

```{r}

gender_employment %>% 
  ggplot(aes(x = year, y = wage_percent_of_male)) +
  geom_jitter(alpha = 0.1) + 
  geom_smooth(method = "lm") + 
  labs(title = "Women's earnings with respect to men's", 
       y = "% of Men's Income", 
       x = "Year")
```

# Question 1\
```{r}
# first let's relevel our categorical variable
gender_employment <- gender_employment %>% 
  mutate(major_category = as.factor(major_category), 
         major_category = relevel(major_category, ref = "Management, Business, and Financial"))

# next, let's create our model
parallel_model <- lm(wage_percent_of_male ~ major_category + year, data = gender_employment)

# lastly, let's summarize the data
library(broom)
tidy(parallel_model)
```
*Can we say anything about overall trends by year?* Each year, the male's wage goes up by 19.2%. \

*1. Calculate the wage percentage of male income for Sales and Office occupations in 2015.*\
$$-80.20 + 6.32 * 0 + 5.76 * 0 + 5.52 * 0 + 4.91 * 0 -1.31 * 0 + 3.33 * 1 + 6.08 * 0 + 0.19 * 2015 = 305.98$$\
(I am confused here because I don't know how to convert this number I got into a percentage (like I did above) or if I should have converted something else before?) ALSO, I decided to use the actual year in the year category because in question 3 they replace year with the actual year.\

MY INTERPRETATION: Sales and Office Occupations male's income percentage will increase in 2015 by 305.98 more than Management, Business, and Financial. (Not sure if the reference category needs to be mentioned with the interpretation)\
*2. Calculate the wage percentage of male income for Service occupations in 2016.*\

$$-80.20 + 6.32 * 0 + 5.76 * 0 + 5.52 * 0 + 4.91 * 0 -1.31 * 0 + 3.33 * 0 + 6.08 * 1 + 0.19 * 2016 =  308.92$$ \

MY INTERPRETATION: Service male's income percentage will increase by 2016 308.92 more than Management, Business, and Financial. \

# Question 2\
```{r}
gender_employment%>% 
  ggplot(aes(x = year, y = wage_percent_of_male)) +
  geom_jitter(alpha = 0.1) + 
  geom_smooth(method = "lm") + 
  labs(title = "Women's earnings with respect to men's", 
       y = "% of Men's Income", 
       x = "Year") + 
  facet_wrap(~major_category, nrow = 2)
```
Looking at this, the parallel rends assumption is not warranted because the slopes are not the same across categories. For example, I notice that the Natural Resources, Construction, and Maintenance group has a much steeper slope than most of the other categories. Additionally, the slope of Service is almost 0, but seems to be slightly negative. \

# Question 3\

Based on this observation, now let's try fitting the model as an interaction.\

```{r}
interaction_model <- lm(wage_percent_of_male ~ major_category * year, data = gender_employment)

# lastly, let's summarize the data
library(broom)
tidy(interaction_model)
```

*What would the estimate be for "Computer, Engineering, and Science" for 2016.*\
(this time, I will only include things in my equation that are "turned on" like in the example, instead of writing out the things that will receive 0s.)\
$$79.40 + 0.72*2016 + 10002.85 * 1 - 0.49 * 2016 * 1 = 10545.93$$\
The estimate for the male wage percentage in computer, engineering, and science for 2016 is 10545.93. 
*What about for Service?*\

$$79.40 + 0.72*2016 + 2137.65 * 1 -1.06 * 2016 * 1 = 1531.61$$\
The estimate for the male wage percentage in service for 2016 is 1531.61.


I notice that the estimates for each are not as close as they were when we used the parallel model. This makes sense as interaction models allow the slopes to be different while the parallel model seems to constrain the slopes so that they can be parallel. \

# Question 4\
*Why would we choose to build a model that assumes parallel trends?*\
The parallel model is easier, and interaction models are more complex. When the complexity is not warranted, there is no reason to use such a complicated model like an interaction. For example, when the slopes seem not to differ as much, then adding the complexity of an interaction model makes no sense.\

# Question 5\

We will start by building a simple model where `wage_percent_of_male` is the outcome variable and `year` is the predictor. \

```{r}
# build model
simple_fit <- lm(wage_percent_of_male ~ year, data = gender_employment)

# summarize
tidy(simple_fit)

```
With every one year increase, there is a 20.14% increase in men's income. \

```{r}
gender_employment %>% 
  select(year, wage_percent_of_male, percent_female) %>% 
  cor(use = "complete.obs")
```
Now we have the correlation coefficients between year, percent of men's income, and percent of females.\

We see pretty weak correlations between the variables (0.02, 0.005, 0.11). \

Now that we see there is weak correlation however, we really want to see if the relationship between year andd the paygap are conditional on the proportion of women who work in an occupation. To do this we will add proportion of women who work in an occupation to our linear model. \

```{r}
# create the model
multiple_fit <- lm(wage_percent_of_male ~ year + percent_female, data = gender_employment)

# summarize
tidy(multiple_fit)
```

It seems that a change in year has more of an impact on men's income than the proportion of women who work in the occupation (19.69% vs. 4.25%). For me this makes sense; however, I did think that there would be a higher impact from the proportion of women within the occupation... even if a negative impact. \

# Question 6\

*Briefly tell me, in your own words, what R-squared is.* R-squared has to do with variation in the dependent variable around the mean that is explained by the model. In other words, the R-squared value shows you the variation around the regression line. 

```{r}

# let's look at the r-squared value for the model without the condition
simple_glanced <- glance(simple_fit)
simple_glanced$r.squared

# let's look at the r-squared value for the model with the condition
multiple_glanced <- glance(multiple_fit)
multiple_glanced$r.squared
```

Since the multiple fit model has a high R-squared value, it seems like this model explains more variation from the dependent variable than the simple model. This means that the multiple variable model is likely a better fit. \

The simple model has an r-squared value of 0.05% and the r-squared value for the multiple variable models is 1.30%.\

